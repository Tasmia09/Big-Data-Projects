{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 594 / CS 690 - Assignment 04 \n",
    "### September 24, 2018\n",
    "---\n",
    "\n",
    "For this assignment, you must work in groups of one or two students. Each person is responsible to write their own code, but the group will (together) discuss their solution.  In this notebook, we provide you with basic functions for completing the assignment.  *Complete the assignment in this notebook.  You will need to modify existing code and write new code to find a solution*.  Each member of the group must upload their own work (i.e., a notebook file) to GitHub.\n",
    "\n",
    "*Note: Running a cell will not rerun previous cells.  If you edit code in previous cells, you must rerun those cells.  If you are having trouble with undefined errors and code changes not applying, we recommend using* `Run All` *to avoid any errors results from not rerunning previous cells.  You can find this in the menu above:* `Cell -> Run All`\n",
    "\n",
    "During lecture 3, we learned about the **MapReduce** programming model.  In this assignment, we will use **MapReduce** programming model to perform the text parsing problems that we solved in assignment 3 *with the power of the MapReduce programming model*.  Python provides a `map` and `reduce` for iterables that do not take advantage of parallel processing (i.e., they are sequential), but they work in a similar way to the parallel implementations you find in *Apache Spark*.  We define three methods (i.e., `mapSequential`, `reduceSequential`, and `reduceByKeySequential`) that extend Python's `map` and `reduce` functions to act like those in *Apache Spark*.  We will use *sequential* **MapReduce** to develop methods that can be used with the *parallel* **MapReduce** from *Apache Spark*.\n",
    "\n",
    "In the following table, we have listed examples of inputs and outputs to different **MapReduce** methods.  See if you can determine how the output was computed with the input:\n",
    "\n",
    "| Input                          | Function   | MapReduce Call | Output               |\n",
    "|--------------------------------|------------|----------------|----------------------|\n",
    "| [1,2,3]                        | f(x)=x+1   | Map            | [2,3,4]              |\n",
    "| [1,2,3]                        | f(x,y)=x+y | Reduce         | 6                    |\n",
    "| [('a', 1), ('b', 2), ('a', 3)] | f(x,y)=x+y | ReduceByKey    | [('a', 4), ('b', 2)] |\n",
    "\n",
    "Now let's check that these functions work with out sequential implementation of `map`, `reduce`, and `reduceByKey`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import functools\n",
    "\n",
    "# We wrap the original python map and reduce functions to be more powerful and resilient\n",
    "def mapSequential(data, func):\n",
    "    return list(map(func, data))\n",
    "\n",
    "def reduceSequential(data, func):\n",
    "    return functools.reduce(func, data)\n",
    "\n",
    "def reduceByKeySequential(data, func):\n",
    "    reduced_data = []\n",
    "    for key, vals in itertools.groupby(sorted(data, key=lambda x: x[0]), key=lambda x: x[0]):\n",
    "        reduced_data.append((key, reduceSequential([x[1] for x in vals], func)))\n",
    "    return reduced_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output 1: [2, 3, 4]\n",
      "Output 2: 6\n",
      "Output 3: [('a', 4), ('b', 2)]\n"
     ]
    }
   ],
   "source": [
    "# Define our three inputs\n",
    "input_1 = [1,2,3]\n",
    "input_2 = [1,2,3]\n",
    "input_3 = [('a', 1), ('b', 2), ('a', 3)]\n",
    "\n",
    "# Define the two functions used\n",
    "def plusOne(x):\n",
    "    return x + 1\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "# Apply our functions to our inputs\n",
    "output_1 = mapSequential(input_1, plusOne)\n",
    "output_2 = reduceSequential(input_2, add)\n",
    "output_3 = reduceByKeySequential(input_3, add)\n",
    "\n",
    "# Print out outputs\n",
    "print('Output 1:', output_1)\n",
    "print('Output 2:', output_2)\n",
    "print('Output 3:', output_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pre-Processing:\n",
    "Below is code to open a text file and return a list of words containing only upper-case unicode characters.  We use this to read the text file (i.e., \"The Count of Monte Cristo\") and prepare the text for the following three problems.  The output, which you should use for solving the assignment problems, is named `words`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regular expressions library\n",
    "import re\n",
    "\n",
    "\n",
    "# Define a method for reading and processing text files\n",
    "def loadText(f_name):\n",
    "    # Read the text file\n",
    "    with open(f_name, 'r') as f:\n",
    "        text_lines = f.readlines()\n",
    "\n",
    "    # Concatenate the list of strings into a single string\n",
    "    text_all = ''.join(text_lines)\n",
    "\n",
    "    # Remove all non-alphabet characters with a regular expression\n",
    "    text_alpha = re.sub(r'[^a-zA-Z]', ' ', text_all)\n",
    "\n",
    "    # Convert characters to upper-case\n",
    "    text_upper = text_alpha.upper()\n",
    "    \n",
    "    # Convert the string of text into a list of words and remove empty words\n",
    "    words = [w for w in text_upper.split(' ') if w is not '']\n",
    "    \n",
    "    return words\n",
    "\n",
    "\n",
    "# Load list of words\n",
    "words = loadText('book_CountOfMonteCristo.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1:\n",
    "Analyze the text for word length frequency. We might expect short words to be more common than long words. But, are words of length 2 more common than words or length 3? Are words of length 3 more common that words of length 4? **Use the pre-processed text, `words`, from the previous cell to count the frequency of each word length in the text using the sequential MapReduce methods we defined above**.  \n",
    "\n",
    "*Complete the definition of functions in the following cell.  These functions are used in the next cell with the `map` and `reduce` calls that we have defined for you above.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return the length of a given word\n",
    "def wordLength(word):\n",
    "    return len(word)\n",
    "\n",
    "# Given a key and value, return a (key, value) pair\n",
    "def makeKeyValue(key, value=1):\n",
    "    return (key,value)\n",
    "\n",
    "# Count (reduce) the values for a given key (word length)\n",
    "def addValues(val1, val2):\n",
    "    return val1 + val2\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Length : Count\n",
      "3           : 109798\n",
      "2           :  84021\n",
      "4           :  81777\n",
      "5           :  49101\n",
      "6           :  39015\n",
      "7           :  30701\n"
     ]
    }
   ],
   "source": [
    "# Map the length of each word\n",
    "word_lengths = mapSequential(words, wordLength)\n",
    "    \n",
    "# Map keyvalue pairs to help count each word length\n",
    "word_keyvalues = mapSequential(word_lengths, makeKeyValue)\n",
    "\n",
    "# ReduceByKey to count number of words with each length\n",
    "word_length_counts = reduceByKeySequential(word_keyvalues, addValues)\n",
    "\n",
    "\n",
    "# Sort word length by most common\n",
    "wl_counts_sorted = sorted(word_length_counts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the 6 most common word lengths\n",
    "print('Word Length : Count')\n",
    "for word_len, count in wl_counts_sorted[:6]:\n",
    "    print('{:<11d} : {:>6d}'.format(word_len, count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "```\n",
    "Word Length : Count\n",
    "3           : 109798\n",
    "2           :  84021\n",
    "4           :  81777\n",
    "5           :  49101\n",
    "6           :  39015\n",
    "7           :  30701\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2:\n",
    "For this problem, it may be beneficial to use another **MapReduce** function from *Apache Spark*: `flatMap`.  We define `flatMapSequential` below.  `flatMap` has the ability to expand the number of elements in a mapped iterable by flattening a list of lists into a single list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatMapSequential(data, func):\n",
    "    mapped_data = mapSequential(data, func)\n",
    "    flattened_data = [item for lst in mapped_data for item in lst]\n",
    "    return flattened_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help you become familiar with `flatMap`, we have an example below which should make the difference between `map` and `flatMap` apparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "map: [[1, 2, 3], [4, 5, 6], [7, 8, 9]]\n",
      "flatmap: [1, 2, 3, 4, 5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# Define a list of lists of integers for testing\n",
    "test = [[1,2,3], [4,5,6], [7,8,9]]\n",
    "\n",
    "# Define a function that returns the input\n",
    "def dummyFunc(x):\n",
    "    return x\n",
    "\n",
    "# Let's apply a map with our dummy function\n",
    "test_map = mapSequential(test, dummyFunc)\n",
    "print('map:', test_map)\n",
    "\n",
    "# Let's apply a flatMap with our dummy function\n",
    "test_flatmap= flatMapSequential(test, dummyFunc)\n",
    "print('flatmap:', test_flatmap)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see the different between `map` and `flatMap`?  If not, modify the code and try it with a different input or different function.  In general, the function with which you call `flatMap` should return an iterable (e.g., list or tuple)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting back to the problem...  Analyze the text for letter frequency. If you’ve taken a crypto course and/or have seen substitution ciphers then you are probably aware that ’e’ is the most common letter used in the English language.  **Use the pre-processed text `words` to count the frequency of each letter in the text using the sequential MapReduce methods we defined above**. \n",
    "\n",
    "*Complete the `splitWord` function in the following cell, then fill in the code in the cell after. Much of this code will be similar to the final cell of Problem 1, including `map` and `reduce` calls using functions defined in Problem 1.  Did you write those functions general enough to be reused?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a word, return an iterable of characters\n",
    "def splitWord(word):\n",
    "    return list(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character : Count\n",
      "E         : 258693\n",
      "T         : 180211\n",
      "A         : 165306\n",
      "O         : 156817\n",
      "I         : 142095\n",
      "N         : 137343\n"
     ]
    }
   ],
   "source": [
    "# The next two calls require you to use a map function.  \n",
    "# Think about which map (i.e., flatMap or Map) is most suitable.\n",
    "\n",
    "# Map list of words to list characters.\n",
    "chars = flatMapSequential(words, splitWord)\n",
    "\n",
    "# Map list of characters to list of key-value pairs.\n",
    "char_keyvalues = mapSequential(chars, makeKeyValue)\n",
    "\n",
    "# ReduceByKey to count number of occurrences of each letter.\n",
    "char_counts = reduceByKeySequential(char_keyvalues, addValues)\n",
    "\n",
    "# Sort letters by most common.\n",
    "char_counts_sorted = sorted(char_counts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the 6 most common characters.\n",
    "print('Character : Count')\n",
    "for character, count in char_counts_sorted[:6]:\n",
    "    print('{:<9} : {:>6}'.format(character, count))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "```\n",
    "Character : Count\n",
    "E         : 258693\n",
    "T         : 180211\n",
    "A         : 165306\n",
    "O         : 156817\n",
    "I         : 142095\n",
    "N         : 137343\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3:\n",
    "For this problem, it may be beneficial to use the `numpy` package.  Specifically, the element-wise addition of numpy array may come in handy.  Below is an example of what happens when you add two numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  a: [1 1 0]\n",
      "  b: [0 1 0]\n",
      "a+b: [1 2 0]\n"
     ]
    }
   ],
   "source": [
    "# Let's see a useful property of numpy arrays\n",
    "# HINT: ref [1]\n",
    "import numpy as np\n",
    "\n",
    "# Define numpy arrays\n",
    "a = np.array([1,1,0])\n",
    "b = np.array([0,1,0])\n",
    "\n",
    "# Print each array and the sum of each array\n",
    "print('  a:', a)\n",
    "print('  b:', b)\n",
    "print('a+b:', a+b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References:**\n",
    "- [1: numpy quickstart](https://docs.scipy.org/doc/numpy-dev/user/quickstart.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we really wanted to crack a substitution cipher (or win on ”Wheel of Fortune”) then we should be aware that, although ’e’ is the most common letter used in English, it may not be the most common first letter in a word. **Count the positional frequencies of each letter using the sequential MapReduce methods we defined above. Specifically, count the number of times each letter appears as the first letter in a word, as the last letter in a word, and as an interior letter in a word (i.e. a letter that is neither first nor last)**.  \n",
    "\n",
    "*Complete the `lettersPosition` function below, then fill in the code in the cell after.  Your functions are used with `map` and `reduce` calls that we have defined.  Note that we use a function that has also been used in Problems 1 and 2. Using numpy arrays in the following function definition could make this assignment easier.  However, you are not required to use numpy.  Feel free to change code by adding more maps or reduces in order to get a correct answer.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a method to return position of each character\n",
    "# You may want to reference your solution from assignment 3\n",
    "# Remember how the reduceByKey will use the returned values when writing a solution\n",
    "def lettersPosition(word):\n",
    "    X = np.identity(3)\n",
    "    X = X.astype(int)\n",
    "    if len(word) == 1:\n",
    "        # Base case for words of length 1\n",
    "        return [(word, X[0,:])]\n",
    "    else:\n",
    "        # Get first and last letters\n",
    "        first, last = word[0], word[-1]\n",
    "        pos_list = [(first, X[0,:]), (last, X[2,:])]\n",
    "\n",
    "        # Get interior letters\n",
    "        interior = word[1:-1]\n",
    "        \n",
    "        for char in interior:\n",
    "            pos_list.append((char, X[1,:]))\n",
    "\n",
    "    return pos_list\n",
    "\n",
    "def addLists(list1, list2):\n",
    "    return np.array(list1) + np.array(list2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character : First | Interior |  Last\n",
      "A         : 51644 |   111686 |  1976\n",
      "B         : 18866 |     8516 |   541\n",
      "C         : 19577 |    32130 |   725\n",
      "D         : 17289 |    18613 | 58075\n",
      "E         : 10178 |   153205 | 95310\n",
      "F         : 17724 |    10618 | 16988\n"
     ]
    }
   ],
   "source": [
    "# Map the location of each character\n",
    "char_positions = flatMapSequential(words, lettersPosition)\n",
    "\n",
    "# ReduceByKey the letter positions for each character\n",
    "char_position_counts = reduceByKeySequential(char_positions, addLists)\n",
    "\n",
    "# Print the position frequency of the first letters in the alphabet\n",
    "print('Character : First | Interior |  Last')\n",
    "for char, char_position in char_position_counts[:6]:\n",
    "    first, interior, last = char_position\n",
    "    print('{:<9} : {:5d} | {:>8d} | {:>5d}'.format(char, first, interior, last))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Output:\n",
    "```\n",
    "Character : First | Interior |  Last\n",
    "A         : 51644 |   111686 |  1976\n",
    "B         : 18866 |     8516 |   541\n",
    "C         : 19577 |    32130 |   725\n",
    "D         : 17289 |    18613 | 58075\n",
    "E         : 10178 |   153205 | 95310\n",
    "F         : 17724 |    10618 | 16988\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4:\n",
    "Repeat Problem 2 with a new text, one you expect to have different letter distribution than The Count of Monty Cristo. You could use something written centuries earlier (e.g., Shakespeare or an early English translation of the Bible), in a distinctive style or genre (e.g., poetry or a contract), or even in a different language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regular expressions library\n",
    "import re\n",
    "\n",
    "\n",
    "# Define a method for reading and processing text files\n",
    "def loadTextFrench(f_name):\n",
    "    # Read the text file\n",
    "    with open(f_name, 'r') as f:\n",
    "        text_lines = f.readlines()\n",
    "\n",
    "    # Concatenate the list of strings into a single string\n",
    "    text_all = ''.join(text_lines)\n",
    "\n",
    "    # Remove all non-alphabet characters with a regular expression\n",
    "    \n",
    "\n",
    "    # Convert characters to upper-case\n",
    "    text_upper = text_all.upper()\n",
    "    \n",
    "    # Convert the string of text into a list of words and remove empty words\n",
    "    words = [w for w in text_upper.split(' ') if w is not '']\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Character : Count\n",
      "E         : 124703\n",
      "S         :  71402\n",
      "A         :  64520\n",
      "N         :  60106\n",
      "T         :  60059\n",
      "I         :  58625\n",
      "R         :  58290\n",
      "U         :  52188\n",
      "L         :  45455\n",
      "O         :  45186\n",
      "D         :  33924\n",
      "C         :  24923\n",
      "M         :  24619\n",
      "P         :  23660\n",
      "\n",
      "         :  17858\n",
      "É         :  16470\n",
      ",         :  15280\n",
      "V         :  11876\n",
      "'         :  10320\n",
      "G         :  10053\n"
     ]
    }
   ],
   "source": [
    "# Place the .txt file in the folder with this Jupyter Notebook, then load it to a list of words.\n",
    "# If your text is in a language with different characters than English, \n",
    "#  you will have to create a modified version of the function loadText().\n",
    "# Load list of words\n",
    "words = loadTextFrench('Douze ans de séjour dans la Haute-Éthiopie.txt')\n",
    "\n",
    "# Compute char_counts_sorted as in Problem 2.\n",
    "chars = flatMapSequential(words, splitWord)\n",
    "\n",
    "# Map list of characters to list of key-value pairs.\n",
    "char_keyvalues = mapSequential(chars, makeKeyValue)\n",
    "\n",
    "# ReduceByKey to count number of occurrences of each letter.\n",
    "char_counts = reduceByKeySequential(char_keyvalues, addValues)\n",
    "\n",
    "# Sort letters by most common.\n",
    "char_counts_sorted = sorted(char_counts, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the 6 most common characters.\n",
    "print('Character : Count')\n",
    "for character, count in char_counts_sorted[:20]:\n",
    "    print('{:<9} : {:>6}'.format(character, count))\n",
    "\n",
    "\n",
    "# Print the most frequent characters to compare with the results from Problem 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to Consider:\n",
    "In this assignment you wrote functions that can be used with the **MapReduce** programming model.  The `map` and `reduce` functions were sequential, but they work in the same way as the parallel versions.  This means that the functions you wrote in this assignment can be used in the next assignment where we use **MapReduce** in parallel with *Apache Spark*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment Questions:\n",
    "**Answer the following questions, in a couple sentences each, in the cells provided below**\n",
    "* List the key tasks you accomplished during this assignment?\n",
    "* Describe the challenges you faced in addressing these tasks and how you overcame these challenges?\n",
    "* Did you work with other students on this assignment? If yes, how did you help them? How did they help you? Be as specific as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answers here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Learnt how to use different functions of MapReduce for example : flatMapSequential, mapSequential and \n",
    "reduceByKeySequential. For problem 3, I learnt to use a identity matrix to identify position of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I only faced challenges in Problem 3. Reducing the keys by its differernt positions was challenging for me and then\n",
    "I used identity matrix and it worked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "My friend and I both discussed Problem 3 as in how we could call the reduce function and then following the given\n",
    "example of adding two arrays with numpy we came to a solution"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
